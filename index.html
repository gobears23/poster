<!DOCTYPE html>
<html lang="en">
<head>
  <title>ARP Example Videos</title>
</head>
<body>

<h1>
Machine Learning to Aid Maritime Domain Awareness<br>
<br>
<a href="#References">Jump to References</a><br />
<br>

Example Videos:
</h1>
<h2>
    DeepStack Object Detection
</h2>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/YxDRv5dg_Mc?controls=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<br>
<h2>
    YOLOv7 Object Detection
</h2>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/wgHrZrrVXWM?controls=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<br>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/An0ZMVzV37Q?controls=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<br>
<iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/6FpwD5p4t3A?controls=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


<br>
<br>
<br>
<br>
<h1 id="References">References:</h1>
<p>
  <html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:12pt;font-family:"Times New Roman";font-style:normal}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c4{font-size:12pt;font-family:"Times New Roman";font-style:italic;font-weight:400}.c5{font-size:12pt;font-family:"Times New Roman";font-weight:400}.c3{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c3 doc-content"><p class="c2"><span class="c1">[1] C. Wang, A. Bochkovskiy and H. M. Liao, &quot;YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors,&quot; 2022.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c5">[2] C. Molnar, G. Casalicchio and B. Bischl, &quot;Interpretable machine learning &ndash; A brief history, state-of-the-art and challenges,&quot; in </span><span class="c4">ECML PKDD 2020 Workshops</span><span class="c1">Anonymous Cham: Springer International Publishing, 2021;2020;, pp. 417-431.</span></p></body></html>
</p>


<br>
</body>
</html>
